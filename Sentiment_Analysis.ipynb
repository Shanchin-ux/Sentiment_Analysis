{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 239:=====================================================> (40 + 1) / 41]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hotel_url: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+------------+-------------------+------+--------------------+--------------------+\n",
      "|           hotel_url|      author|               date|rating|               title|                text|\n",
      "+--------------------+------------+-------------------+------+--------------------+--------------------+\n",
      "|Hotel_Review-g194...|violettaf340|2019-01-01 00:00:00|   5.0|        Xmas holiday|We went here with...|\n",
      "|Hotel_Review-g194...|   Lagaiuzza|2016-01-01 00:00:00|   5.0|  Baltic, what else?|We have spent in ...|\n",
      "|Hotel_Review-g194...|  ashleyn763|2014-10-01 00:00:00|   5.0|Excellent in ever...|I visited Hotel B...|\n",
      "|Hotel_Review-g194...| DavideMauro|2014-08-01 00:00:00|   5.0|The house of your...|I've travelled qu...|\n",
      "|Hotel_Review-g194...|    Alemma11|2013-08-01 00:00:00|   4.0|A paradise for ch...|We decided for th...|\n",
      "+--------------------+------------+-------------------+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Large Dataset Import\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/Users/swagatkumarpanda/Downloads/HotelCSVOutputs/output_part_1.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the schema of the dataframe\n",
    "df.printSchema()\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial row count: 6598369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 244:=====================================================> (40 + 1) / 41]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final row count: 6598291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the total number of rows before cleaning\n",
    "initial_row_count = df.count()\n",
    "print(f\"Initial row count: {initial_row_count}\")\n",
    "\n",
    "# Perform data cleaning\n",
    "# For example, let's remove rows with any null values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check the total number of rows after cleaning\n",
    "final_row_count = df_cleaned.count()\n",
    "print(f\"Final row count: {final_row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rating: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+------+--------------------+\n",
      "|rating|                text|\n",
      "+------+--------------------+\n",
      "|   5.0|We went here with...|\n",
      "|   5.0|We have spent in ...|\n",
      "|   5.0|I visited Hotel B...|\n",
      "|   5.0|I've travelled qu...|\n",
      "|   4.0|We decided for th...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'author' column from the cleaned dataframe\n",
    "df_cleaned = df_cleaned.drop('author','date','title','hotel_url')\n",
    "\n",
    "# Show the schema of the dataframe after dropping the column\n",
    "df_cleaned.printSchema()\n",
    "\n",
    "# Show the first few rows of the dataframe after dropping the column\n",
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+\n",
      "|                text|rating|prediction|\n",
      "+--------------------+------+----------+\n",
      "|We went here with...|   5.0|       5.0|\n",
      "|We have spent in ...|   5.0|       5.0|\n",
      "|I visited Hotel B...|   5.0|       5.0|\n",
      "|I've travelled qu...|   5.0|       5.0|\n",
      "|We decided for th...|   4.0|       4.0|\n",
      "+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6737455952547019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 827:=====================================================> (40 + 1) / 41]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+\n",
      "|                text|rating|prediction|\n",
      "+--------------------+------+----------+\n",
      "|               dirty|   1.0|       1.0|\n",
      "|\"\"\"non smoking\"\" ...|   1.0|       1.0|\n",
      "|\"A number of issu...|   1.0|       1.0|\n",
      "|\"Accommodation in...|   1.0|       4.0|\n",
      "|\"After 17 yrs of ...|   1.0|       1.0|\n",
      "+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Tokenize the text column\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "# Apply HashingTF to convert words to term frequency vectors\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "# Apply IDF to rescale the term frequency vectors\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression(labelCol=\"rating\", featuresCol=\"features\")\n",
    "\n",
    "# Create a pipeline with the stages\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
    "\n",
    "# Fit the pipeline to the cleaned dataframe\n",
    "model = pipeline.fit(df_cleaned)\n",
    "\n",
    "# Make predictions on the cleaned dataframe\n",
    "predictions = model.transform(df_cleaned)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"text\", \"rating\", \"prediction\").show(5)\n",
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "train_data, test_data = df_cleaned.orderBy(rand()).randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"text\", \"rating\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the path where you want to save the model\n",
    "model_save_path = \"/Users/swagatkumarpanda/Downloads/HotelCSVOutputs/spark_model\"\n",
    "\n",
    "# Save the model using Spark's save method\n",
    "model.save(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
